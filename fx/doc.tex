\documentclass[a4paper, titlepage,12pt]{article}
\usepackage[margin=3.7cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[swedish,english]{babel}
\usepackage{csquotes}
\usepackage[hyphens]{url}
\usepackage{amsmath,amssymb,amsthm, amsfonts}
\usepackage[backend=biber,citestyle=ieee]{biblatex}
\usepackage[yyyymmdd]{datetime}
\usepackage{titlesec} 

\titleformat{\subsection}[runin]
  {\normalfont\large\bfseries}{\thesubsection}{1em}{}
\titleformat{\subsubsection}[runin]
  {\normalfont\normalsize\bfseries}{\thesubsubsection}{1em}{}

\addbibresource{literature.bib}

\title{Completion Distributed Systems}

\author{Adam Temmel (adte1700)}

\begin{document}
	\maketitle

	\section*{Question 1}
	\emph{What is a scalable system? What are the main methods to make a system more scalable?}
\\\\
	A scalable system can grow in regards to one or several aspects without suffering in regards to performance. These include: number of components, geographical size or amount/size of administrative domains. This can be achieved through distribution, replication and caching.

	\section*{Question 2}
	\emph{What kind of operations should use at-most-once semantics? What kind of operations do not need to use at-most-once semantics? Explain the design choices that are relevant to minimizing the amount of reply data held at a server for implementing at-most-once semantics. Compare the storage requirements when the RR and RRA protocols are used.}
\\\\
	A good example of an operation that should use at-most-once semantics are those who need to perform transactions, e.g bank transactions. An operation that definitely does not need at-most-once semantics is a video stream. RR assumes that a new request message is a validation that the previous response completed successfully. Therefore, it should hold a response message until the next request shows up. RRA on the other hand specifies a reply message to only be held until an acknowledgement is received.

	\section*{Question 3}
	\emph{An NTP server B receives server A's message at 10:00:01.200 bearing a timestamp 10:00:01.120 and replies to it. Then, A receives the message at 10:00:20.500 bearing B's timestamp 10:00:20.560.}
	\subsection*{a)}
	\emph{Use NTP method to estimate:}
	\subsubsection*{1)} \emph{the offset between B and A}
\\\\
	$\theta = \frac{(t_1 - t_0) + (t_2 - t_3)}{2} = \frac{((0.200 - 0.120) + (0.560 - 0.500)}{2} = \frac{0.080 + 0.060}{2} = \frac{0.140}{2} = 0.070s$
	\subsubsection*{2)} \emph{the accuracy of the estimate.}
\\\\
	$\theta_{accuracy} = \frac{t_3 - t_0 - t_2 + t_1}{2} = \frac{0.500 - 0.120 - 0.560 + 0.200}{2} = \frac{0.700 - 0.680}{2} = \frac{0.020}{2} = 0.010s$
	\subsection*{b)}
	\emph{Suppose that if the minimum round trip is 20 ms, using Christian's algorithm to decide:}
	\subsubsection*{1)} \emph{The time A should set for synchronizing A to B}
\\\\
	$A^{new} = t_2 + \frac{RTT}{2} = 10:00:20.560 + \frac{t_3 - t_0}{2} = 10:00:20.560 + \frac{19.38}{2} = 10:00:20.560 + 9.69 = 10:00:30.25$
	\subsubsection*{2)} \emph{Estimate the accuracy of this setting.}
\\\\
	$A^{new}_{accuracy} = \frac{RTT}{2} - min = 9.69 - 0.020 = 9.67s$

	\section*{Question 4}
	\emph{For the distributed system shown in the figure below (not pictured).}
	\subsection*{1)}
	\emph{Provide logical time for all the events using:}
	\subsubsection*{a)} 
	\emph{Global logical time}
\\\\
	$A_1 = (1, 1), B_1 = (2, 2), C_1 = (1, 3), B_2 = (3, 2), A_2 = (2, 1), C_2 = (2, 3), A_3 = (3, 1), B_3 = (4, 2), A_4 = (4, 1), C_3 = (5, 3), B_4 = (5, 2), C_4 = (6, 3)$
	\subsubsection*{b)}
	\emph{Vector time}
\\\\
	$A_1 = (1, 0, 0), B_1 = (1, 1, 0), C_1 = (0, 0, 1), A_2 = (2, 0, 0), B_2 = (1, 2, 1), C_2 = (0, 0, 2), A_3 = (3, 0, 2), B_3 = (2, 3, 1), A_4 = (4, 0, 2), C_3 = (4, 0, 3), B_4 = (2, 4, 1), C_4 = (4, 4, 4)$
	\subsection*{2)}
	\emph{For each of the following global states, decide if it is consistent, transitless and strong consistent.}
	\subsubsection*{<A1,B2,C1>} is consistent, transitless and therefore also strong consistent.
	\subsubsection*{<A2,B2,C2>} is consistent.
	\subsubsection*{<A3,B3,C3>} is transitless.

	\section*{Question 5}
	\emph{In a certain system, each process typically uses a critical section many times before another process requires it. Explain why Ricart and Agrawala's multicast-based mutual exclusion algorithm is inefficient for this case, and describe how to improve its performance. Does your adaption satisfy liveness condition ME2?}
\\\\
	This particular algorithm requires a reply from all other processes before letting a process enter the critical section. The problem this system will have by using this algorithm is that a lot of messages will need to be sent and received for each individual accessing of the critical section. A solution to this problem is that each process that requests access to the critical section keeps access to the critical section until access is requested again. By doing so, sending and receiving of messages is limited to when the access to the critical section needs to be transfered. This satisfies liveness condition ME2, but not ME3.

	\section*{Question 6}
	\emph{Suppose that $P_1, P_2, ..., P_7$ are in one group. The group will use bully algorithm to select a new coordinator. $P_7$ was coordinator. $P_7$ just crashed. If $P_4$ find that $P_7$ has been crashed...}
	\subsection*{a)}
	\emph{What will $P_4$ do?} 
\\\\
	$P_4$ will send an election message to all processes with a higher process id than itself ($P_5, P_6$).
	\subsection*{b)} \emph{If during the election time, no any other process will crash, how many messages will be sent to select a new coodinator?}
\\\\
	$P_4$ sends election start message to $P_5$ and $P_6$. $(+2)$
\\\\
	$P_4$ receives alive messages from $P_5$ and $P_6$. $(+2)$
\\\\
	$P_5$ sends to $P_6$ and $P_7$ resulting in one alive message in return. $(+3)$
\\\\
	$P_6$ sends to $P_7$ and gets no response. $(+1)$
\\\\
	$P_6$ sends a victory message to all other processes. $(+5)$
\\\\
	The sum is $2 + 2 + 3 + 1 + 5 = 13$.

	\section*{Question 7}
	\emph{What is monotonic write consistency? Describe a simple implementation of monotonic write consistency.}
\\\\
	A write operation by a given process on a data item is completed before any successive write operation on the same data item by another process may be done. If another process wishes to perform a write operation, writes done by other processes need to be propagated to the process who wishes to perform the next write.

	\section*{Question 8}
	\emph{Briefly describe coordinated check point algorithm. Explain which actions in coordinate check point algorithm guarantee the recorded global states are consistency? Are these global states transitless?}
\\\\
	The check point algorithms takes checkpoints every time the global state is consistent. This is done in two phases so as to assert that the state actually is consistent. If there is a global state that isn't consistent, the algorithm 'rewinds' to the checkpoint where the system was consistent.
\begin{itemize}
	\item A coordinator multicasts a sync order.
	\item When the other processes receive this order, they take a local checkpoint and queue any subsequent messages that might occur.
	\item The processes then send an ACK to the coordinator.
	\item Upon receiving an ACK from all the other processes, the coordinator multicasts that the checkpoint is completed.
\end{itemize}

	\section*{Question 9}
	\emph{Briefly describe iterative name resolution and recursive name resolution. Compare the advantages and disadvantages of these two kinds of name resolutions.}
\\\\
	Iterative name resolution returns the result of each individual lookup back to the lookup origin. This causes the total resolution time to increase, as the amounts of messages needed to be sent increases. Recursive name resolution forwards individual lookups to each individual nameserver, and does not stop doing so until it has the final result, which it returns to the lookup origin. Recursive name resolution is therefore much faster, but also more prone to overloading attacks, as a core part of the idea revolves around forwarding requests from server to server, whereas an iterative resolution primarily holds the lookup origin responsible for the resolution process. As such, it is not a bad idea to mix these two methods, using iterative name resolution for nameservers that are expected to be exposed to heavy load (such as root nameserves) and instead saving recursive name resolution for nameservers who are exposed to less traffic.

	\section*{Question 10}
	\emph{Suppose that the closed group g includes $P_1$, $P_2$ and $P_3$. Given the multicast pairs: $<A_1, C_1>, <C_1, B_1>, <A_2, B_1>, <A_1, A_2>, <A_1, B_2>, <B_1, B_2>$}
	\subsection*{1)}
	\emph{For each of the above multicast pairs, decide if it is causal order.}
\\\\
		$<A_1, C_1>, <C_1, B_1>, <A_2, B_1>, <A_1, A_2>, <A_1, B_2>$ are causally ordered.
	\subsection*{2)}
	\emph{For each of the above multicast pairs, decide if it is FIFO order.}
\\\\
		$<A_1, C_1>, <C_1, B_1>, <A_2, B_1>, <A_1, A_2>, <A_1, B_2>$ are FIFO ordered.
	\subsection*{3)}
	\emph{For each of the above multicast pairs, decide if it is total order.}
\\\\
		$<A_1, C_1>, <C_1, B_1>, <A_1, A_2>, <A_1, B_2>$ are totally ordered in regards to each other.
\end{document}
